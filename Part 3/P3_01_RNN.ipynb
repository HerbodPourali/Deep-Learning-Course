{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k19nt3xbtmLF"
      },
      "source": [
        "<img src='sharif_logo.png' alt=\"SUT logo\" width=150 height=150 align=left class=\"saturate\" >\n",
        "\n",
        "<br>\n",
        "<font face=\"Times New Roman\">\n",
        "<div dir=ltr align=center>\n",
        "<font color=0F5298 size=7>\n",
        " Deep Learning <br>\n",
        "<font color=2565AE size=5>\n",
        "Computer Engineering Department - Spring 2025  <br>\n",
        "<font color=3C99D size=5>\n",
        "          Homework 3: Practical - Oil Price Forecasting\n",
        " <br>\n",
        "<font color=696880 size=4>\n",
        "            Designer: Mohammad Amanlou\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqV-wqAFtmLG"
      },
      "source": [
        "# üõ¢Ô∏è Oil Price Prediction using Time Series Models üìà\n",
        "\n",
        "This notebook is designed for students to complete tasks related to oil price prediction using different machine learning models. üöÄ\n",
        "\n",
        "## üìö References\n",
        "- üìä [Dataset: Yahoo Finance - CL=F](https://finance.yahoo.com/quote/CL=F/history/)\n",
        "- üìÑ [Reference Paper](https://www.ijournalse.org/index.php/ESJ/article/view/21497)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVUDQCvbtmLG"
      },
      "source": [
        "## 1Ô∏è‚É£ Introduction\n",
        "üîç One of the most common applications of recurrent neural networks is **time series forecasting**. In this assignment, you will predict **crude oil prices** using four different methods. üí°\n",
        "\n",
        "## 2Ô∏è‚É£ Dataset and Preprocessing (25 Points)\n",
        "\n",
        "### üì• 2.1 Download Dataset\n",
        "üìå Download the dataset from **Yahoo Finance** for `CL=F` from **2010 to the present**.\n",
        "[Yahoo Finance - CL=F](https://finance.yahoo.com/quote/CL=F/history/)\n",
        "\n",
        "### üéØ 2.2 Select Features\n",
        "‚úÖ Select the `Adj Close` column as the **main feature**.\n",
        "\n",
        "### ‚ö†Ô∏è **2.3 Handle Missing Data**\n",
        "\n",
        "You will encounter missing data (`null` values) within your dataset. Follow these detailed steps carefully to handle the missing values and create a complete, reliable dataset:\n",
        "\n",
        "#### üìù Step 1: Introduce Random Missing Data\n",
        "- Identify all indices in the `Adj Close` column that currently have valid (non-null) data.\n",
        "- Set a random seed (`np.random.seed(42)`) for reproducibility.\n",
        "- Randomly select **10%** of these valid indices and set their values to `NaN`.\n",
        "\n",
        "#### üîç Step 2: Identify Missing Values\n",
        "- Identify all dates where at least one column has a missing value (`NaN`).\n",
        "- Print the number of missing dates and the total number of dates to evaluate the extent of missingness.\n",
        "\n",
        "#### üîß Step 3: Replace Missing Values\n",
        "- Create a copy of the `Adj Close` column for filling purposes.\n",
        "- First, apply **linear interpolation** to estimate missing values based on surrounding data points.\n",
        "- Then, use backward fill (`bfill`) followed by forward fill (`ffill`) methods to handle any remaining missing values at the start or end of the dataset.\n",
        "\n",
        "#### üéØ Outcome:\n",
        "After completing these steps, your dataset will have no missing values in the `Adj Close` column, ready for further analysis or modeling.\n",
        "\n",
        "üõ† *Your task:* Implement the missing data handling methods below. (16 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXqVJAF7GWRZ",
        "outputId": "53f3dc40-7ca6-4c10-f491-dc4a2eb77aae"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.24.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySo5XByPpgP0",
        "outputId": "77fb95d5-b580-4a45-c769-039265e26f09"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-07T19:47:41.051690Z",
          "iopub.status.busy": "2025-04-07T19:47:41.051344Z",
          "iopub.status.idle": "2025-04-07T19:47:42.111469Z",
          "shell.execute_reply": "2025-04-07T19:47:42.110459Z",
          "shell.execute_reply.started": "2025-04-07T19:47:41.051662Z"
        },
        "id": "ptdffWBLIgbe",
        "outputId": "51455846-737c-4af0-a808-572fd9d75be0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# TO Do: Read the data and pring 5 examples\n",
        "\n",
        "data = yf.download('CL=F', start='2010-01-01', end='2025-05-04', auto_adjust=False)\n",
        "\n",
        "# Select the 'Adj Close' column as the main feature\n",
        "adj_close_data = data[['Adj Close']]\n",
        "\n",
        "# Reset the index to replace dates with numeric indices (0, 1, 2, 3,...)\n",
        "adj_close_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the first 5 rows of the dataset\n",
        "print(adj_close_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-07T19:47:44.101798Z",
          "iopub.status.busy": "2025-04-07T19:47:44.101444Z",
          "iopub.status.idle": "2025-04-07T19:47:44.110658Z",
          "shell.execute_reply": "2025-04-07T19:47:44.109780Z",
          "shell.execute_reply.started": "2025-04-07T19:47:44.101771Z"
        },
        "id": "zC2nt8fuKTFN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# TO DO: Introduce random null\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Identify valid (non-null) indices in the 'Adj Close' column\n",
        "valid_indices = adj_close_data[adj_close_data['Adj Close'].notnull()].index\n",
        "\n",
        "# Randomly select 10% of valid indices and set their values to NaN\n",
        "missing_indices = np.random.choice(valid_indices, size=int(len(valid_indices) * 0.1), replace=False)\n",
        "\n",
        "# Set the selected indices to NaN\n",
        "adj_close_data.loc[missing_indices, 'Adj Close'] = np.nan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-07T19:47:44.321368Z",
          "iopub.status.busy": "2025-04-07T19:47:44.321077Z",
          "iopub.status.idle": "2025-04-07T19:47:44.327735Z",
          "shell.execute_reply": "2025-04-07T19:47:44.326950Z",
          "shell.execute_reply.started": "2025-04-07T19:47:44.321345Z"
        },
        "id": "zCg_o1gRLHW5",
        "outputId": "2ec73d6e-5164-4143-8127-9df27d0c8ee1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# TO DO: Identify missing dates and null values\n",
        "\n",
        "# Identify all dates where there is at least one missing value (NaN)\n",
        "missing_dates = adj_close_data[adj_close_data.isnull().any(axis=1)].index\n",
        "\n",
        "# Calculate the number of missing dates and total dates\n",
        "num_missing_dates = len(missing_dates)\n",
        "num_all_dates = len(adj_close_data)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Num of missing dates: {num_missing_dates}\")\n",
        "print(f\"Num of all dates: {num_all_dates}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-07T19:47:44.501759Z",
          "iopub.status.busy": "2025-04-07T19:47:44.501448Z",
          "iopub.status.idle": "2025-04-07T19:47:44.512235Z",
          "shell.execute_reply": "2025-04-07T19:47:44.511334Z",
          "shell.execute_reply.started": "2025-04-07T19:47:44.501737Z"
        },
        "id": "F3o85YlGLrEl",
        "outputId": "83c27379-2dae-48e0-c7cc-37884b92b295",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# TO DO: Fill missing values using .interpolate or .fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "# Create a copy of the 'Adj Close' column for filling\n",
        "adj_close_filled = adj_close_data['Adj Close'].copy()\n",
        "\n",
        "# Step 1: Apply linear interpolation to estimate missing values\n",
        "adj_close_filled = adj_close_filled.interpolate(method='linear')\n",
        "\n",
        "# Step 2: Use backward fill (bfill) and then forward fill (ffill) to handle any remaining missing values\n",
        "adj_close_filled = adj_close_filled.fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "# Update the original dataset with the filled values\n",
        "adj_close_data['Adj Close'] = adj_close_filled\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAu1-1YftmLI"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "### ‚úÇÔ∏è 2.4 Train-Test Split and Normalization\n",
        "- **Split** the dataset into **training and test sets** based on the ratio given in the reference paper.\n",
        "- **Normalize** the data.\n",
        "\n",
        "üìÑ [Reference Paper](https://www.ijournalse.org/index.php/ESJ/article/view/21497)\n",
        "\n",
        "üõ† *Your task:* Implement the splitting and normalization below. (4 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-07T19:47:44.790019Z",
          "iopub.status.busy": "2025-04-07T19:47:44.789778Z",
          "iopub.status.idle": "2025-04-07T19:47:44.803986Z",
          "shell.execute_reply": "2025-04-07T19:47:44.803028Z",
          "shell.execute_reply.started": "2025-04-07T19:47:44.790000Z"
        },
        "id": "ZzQ_j8YGM0Aw",
        "outputId": "bf145698-6eb3-481e-d171-ce398b80b769",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def temporal_split(series, train_ratio=0.6, val_ratio=0.2):\n",
        "    total_samples = len(series)\n",
        "    train_size = int(total_samples * train_ratio)\n",
        "    remaining_size = total_samples - train_size\n",
        "    val_size = int(remaining_size * val_ratio)\n",
        "\n",
        "    # Define the splits based on the indices\n",
        "    train = series[:train_size]\n",
        "    val = series[train_size:train_size + val_size]\n",
        "    test = series[train_size + val_size:]\n",
        "\n",
        "    return train, val, test\n",
        "\n",
        "train_list, val_list, test_list = [], [], []\n",
        "\n",
        "# Split the data using temporal split\n",
        "train, val, test = temporal_split(adj_close_data)\n",
        "train_list.append(train)\n",
        "val_list.append(val)\n",
        "test_list.append(test)\n",
        "\n",
        "train_data = pd.concat(train_list)\n",
        "val_data = pd.concat(val_list)\n",
        "test_data = pd.concat(test_list)\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training data\n",
        "train_data['Adj Close'] = scaler.fit_transform(train_data[['Adj Close']])\n",
        "\n",
        "# Transform the validation and test data using the same scaler\n",
        "val_data['Adj Close'] = scaler.transform(val_data[['Adj Close']])\n",
        "test_data['Adj Close'] = scaler.transform(test_data[['Adj Close']])\n",
        "\n",
        "# Print the sample of training and testing data\n",
        "print(\"Training data sample:\")\n",
        "print(train_data.head())\n",
        "print(\"Testing data sample:\")\n",
        "print(test_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcww22DhtmLI"
      },
      "source": [
        "### üìä 2.5 Data Visualization\n",
        "- **Plot a histogram** similar to **Figure 6** in the reference paper, showing the **distribution of oil prices**.\n",
        "\n",
        "üõ† *Your task:* Implement the histogram plot below. (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "execution": {
          "iopub.execute_input": "2025-04-07T19:47:47.411363Z",
          "iopub.status.busy": "2025-04-07T19:47:47.411078Z",
          "iopub.status.idle": "2025-04-07T19:47:47.666718Z",
          "shell.execute_reply": "2025-04-07T19:47:47.665845Z",
          "shell.execute_reply.started": "2025-04-07T19:47:47.411342Z"
        },
        "id": "M6ajp4iWRHlr",
        "outputId": "dd53a3bf-e3b8-423e-a873-b4e9f9e1cd93",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# TO DO: Plot histogram of 'Adj Close'\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(adj_close_data['Adj Close'], bins=15, color='gray', edgecolor='black', alpha=0.7)\n",
        "plt.title(\"Histogram of 'Adj Close'\")\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "#plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhHiPzyAtmLJ"
      },
      "source": [
        "## 3Ô∏è‚É£ Implementing Deep Learning Models ü§ñ (60 Points)\n",
        "\n",
        "The reference paper utilizes **three models** for time series forecasting:\n",
        "- `RNN`\n",
        "- `LSTM`\n",
        "- `GRU`\n",
        "\n",
        "üìå **Train** each model using the **hyperparameters** given in **Table 4** of the paper.\n",
        "üìå Use `Mean Square Error (MSE)` as the **loss function**.\n",
        "\n",
        "üìÑ [Reference Paper](https://www.ijournalse.org/index.php/ESJ/article/view/21497)\n",
        "\n",
        "\n",
        "### Important Details & Clarifications\n",
        "\n",
        "- **What to Predict?**  \n",
        "  The goal is to predict **the actual next-day price** (regression problem), rather than just identifying price increase or decrease.\n",
        "  \n",
        "- **Input/Output Structure:**  \n",
        "  - **Input:** A window of \\( k \\) consecutive daily prices (e.g., 50 days).  \n",
        "  - **Output:** The predicted price for the next day.\n",
        "  \n",
        "- **How to Evaluate?**  \n",
        "  Use the four metrics (RMSE, MAE, MAPE, \\( R^2 \\)) to gauge how accurately your model tracks the real price values.\n",
        "\n",
        "- **Target Accuracy:**  \n",
        "  Your accuracy might differ from the paper‚Äôs due to factors like data splitting, normalization, or different random seeds. However, aim to closely replicate the paper‚Äôs results or provide justifications for any discrepancy.\n",
        "\n",
        "**Final Deliverables:**\n",
        "1. **All four trained models** (RNN, LSTM, GRU).  \n",
        "2. **Comparison plots** of predicted vs. actual values (in both normalized and original price scales, if desired).  \n",
        "3. **Performance metrics** (RMSE, MAE, MAPE, \\( R^2 \\)) for each model, presented in a table or a concise summary.\n",
        "\n",
        "\n",
        "üõ† *Your task:* Implement these models below. (30 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-07T19:47:50.610188Z",
          "iopub.status.busy": "2025-04-07T19:47:50.609868Z",
          "iopub.status.idle": "2025-04-07T19:47:50.637707Z",
          "shell.execute_reply": "2025-04-07T19:47:50.636840Z",
          "shell.execute_reply.started": "2025-04-07T19:47:50.610161Z"
        },
        "id": "9eJE-U1tVc60",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def create_sequences(data, window_size):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for i in range(len(data) - window_size):\n",
        "        seq = data[i:i+window_size]\n",
        "        label = data[i+window_size]\n",
        "        sequences.append(seq)\n",
        "        labels.append(label)\n",
        "    return np.array(sequences), np.array(labels)\n",
        "\n",
        "window_size = 50\n",
        "#TO DO: make test and train loader\n",
        "\n",
        "# Prepare the sequence data from normalized training and test sets\n",
        "train_seq, train_labels = create_sequences(train_data['Adj Close'].values, window_size)\n",
        "test_seq, test_labels = create_sequences(test_data['Adj Close'].values, window_size)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_seq_tensor = torch.tensor(train_seq, dtype=torch.float32).unsqueeze(-1)\n",
        "train_labels_tensor = torch.tensor(train_labels, dtype=torch.float32).unsqueeze(-1)\n",
        "test_seq_tensor = torch.tensor(test_seq, dtype=torch.float32).unsqueeze(-1)\n",
        "test_labels_tensor = torch.tensor(test_labels, dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(train_seq_tensor, train_labels_tensor)\n",
        "test_dataset = TensorDataset(test_seq_tensor, test_labels_tensor)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-07T19:47:52.581811Z",
          "iopub.status.busy": "2025-04-07T19:47:52.581473Z",
          "iopub.status.idle": "2025-04-07T19:57:44.169073Z",
          "shell.execute_reply": "2025-04-07T19:57:44.168090Z",
          "shell.execute_reply.started": "2025-04-07T19:47:52.581787Z"
        },
        "id": "Ba-A5samtmLJ",
        "outputId": "8b87eb94-3813-4d72-d010-1ed86ce5f5a3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# LSTM\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=512, num_layers=1, output_size=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 4:\n",
        "          x = x.squeeze(-1)\n",
        "\n",
        "        # Initialize hidden state and cell state\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: (batch, seq_len, hidden)\n",
        "        out = out[:, -1, :]              # get the output of the last time step\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "lstm_model = LSTMModel()\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=50):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "train_model(lstm_model, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-07T19:57:44.170458Z",
          "iopub.status.busy": "2025-04-07T19:57:44.170217Z",
          "iopub.status.idle": "2025-04-07T20:03:26.792888Z",
          "shell.execute_reply": "2025-04-07T20:03:26.792067Z",
          "shell.execute_reply.started": "2025-04-07T19:57:44.170438Z"
        },
        "id": "6iY-myLEtmLJ",
        "outputId": "8330f0e0-2525-4075-96ee-4e621e866467",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=512, num_layers=1, output_size=1):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 4:\n",
        "          x = x.squeeze(-1)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]\n",
        "        return self.fc(out)\n",
        "\n",
        "rnn_model = RNNModel()\n",
        "optimizer = torch.optim.Adam(rnn_model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "train_model(rnn_model, train_loader, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-07T20:03:26.794942Z",
          "iopub.status.busy": "2025-04-07T20:03:26.794583Z",
          "iopub.status.idle": "2025-04-07T20:10:03.550712Z",
          "shell.execute_reply": "2025-04-07T20:10:03.549977Z",
          "shell.execute_reply.started": "2025-04-07T20:03:26.794912Z"
        },
        "id": "uj-VzX78tmLJ",
        "outputId": "e9914174-f1b0-4bf3-bfd7-4df451377e89",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# GRU\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=512, num_layers=1, output_size=1):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 4:\n",
        "          x = x.squeeze(-1)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.gru(x, h0)\n",
        "        out = out[:, -1, :]\n",
        "        return self.fc(out)\n",
        "\n",
        "gru_model = GRUModel()\n",
        "optimizer = torch.optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "train_model(gru_model, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9CrTgtQtmLK"
      },
      "source": [
        "### üìà 3.1 Prediction and Evaluation\n",
        "1. **Prediction:** After training, generate predictions for the test set (i.e., predict the next-day price based on the preceding \\( k \\) days).\n",
        "2. **Visualization:** **Plot the predicted values** alongside the **actual values** for each model. This comparison helps in visually assessing each model‚Äôs performance.\n",
        "\n",
        "üõ† **Your Task:** Implement the **visualization of predictions** (15 Points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-07T20:10:03.551946Z",
          "iopub.status.busy": "2025-04-07T20:10:03.551712Z",
          "iopub.status.idle": "2025-04-07T20:10:05.949475Z",
          "shell.execute_reply": "2025-04-07T20:10:05.948572Z",
          "shell.execute_reply.started": "2025-04-07T20:10:03.551926Z"
        },
        "id": "1Wr7cosYtmLK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Predictions\n",
        "def predict(model, data_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "      for x_batch, y_batch in data_loader:\n",
        "          y_pred = model(x_batch)\n",
        "          predictions.append(y_pred.squeeze().cpu().numpy())\n",
        "          actuals.append(y_batch.squeeze().cpu().numpy())\n",
        "    return np.concatenate(predictions), np.concatenate(actuals)\n",
        "\n",
        "#TO DO: predict real outputs\n",
        "lstm_preds, lstm_targets = predict(lstm_model, test_loader)\n",
        "rnn_preds, rnn_targets = predict(rnn_model, test_loader)\n",
        "gru_preds, gru_targets = predict(gru_model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2025-04-07T20:10:05.950691Z",
          "iopub.status.busy": "2025-04-07T20:10:05.950426Z",
          "iopub.status.idle": "2025-04-07T20:10:07.171958Z",
          "shell.execute_reply": "2025-04-07T20:10:07.171092Z",
          "shell.execute_reply.started": "2025-04-07T20:10:05.950671Z"
        },
        "id": "aQqtGTrXtmLK",
        "outputId": "d0ed8a1b-6c3f-496d-c889-88d4ebd79830",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_predictions(predictions, actual, model_name):\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(actual, label=\"Actual Values\", color='blue')\n",
        "    plt.plot(predictions, label=f\"{model_name} Predictions\", color='orange')\n",
        "    plt.title(f\"{model_name} Predictions vs Actual Values\")\n",
        "    plt.xlabel(\"Time Step\")\n",
        "    plt.ylabel(\"Normalized Price\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "#TO DO: plot all models predictions on all data\n",
        "\n",
        "plot_predictions(lstm_preds, lstm_targets, \"LSTM\")\n",
        "plot_predictions(gru_preds, gru_targets, \"GRU\")\n",
        "plot_predictions(rnn_preds, rnn_targets, \"RNN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUsLeP02tmLK"
      },
      "source": [
        "### üìä 3.2 Error Metrics\n",
        "üìå Explain the following **error metrics** used in the paper:\n",
        "- `RMSE` (Root Mean Square Error)\n",
        "\n",
        "  Measures the square root of the average squared differences between predicted and actual values.  \n",
        "    It penalizes larger errors more than smaller ones, making it sensitive to outliers.  \n",
        "    ‚û§ Lower RMSE = better performance.  \n",
        "    \n",
        "    **Formula:**  \n",
        "    \n",
        "  $$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n",
        "  \n",
        "- `MAE` (Mean Absolute Error)\n",
        "\n",
        "  Measures the average of the absolute differences between predicted and actual values.  \n",
        "  It treats all errors equally and is more robust to outliers.  \n",
        "  ‚û§ Lower MAE = better accuracy.\n",
        "  \n",
        "  **Formula:**  \n",
        "  \n",
        "  $$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
        "\n",
        "\n",
        "- `MAPE` (Mean Absolute Percentage Error)\n",
        "\n",
        "  Measures the average absolute percentage difference between predicted and actual values.  \n",
        "  Expresses error as a percentage, making it easier to interpret.  \n",
        "  ‚û§ Lower MAPE = better model, but it may be unstable when actual values are close to zero.\n",
        "  \n",
        "  **Formula:**  \n",
        "  \n",
        "  $$\\text{MAPE} = \\frac{100\\%}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right|$$\n",
        "- `R-Squared` (Coefficient of Determination)\n",
        "\n",
        "  Indicates how well the model explains the variance in the actual data.  \n",
        "  Ranges from 0 (no explanatory power) to 1 (perfect prediction).  \n",
        "  ‚û§ Higher R¬≤ = better model fit.\n",
        "  \n",
        "  **Formula:**  \n",
        "  \n",
        "  $$R^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}$$\n",
        "\n",
        "**üìå Instruction:**  \n",
        "Explain each of these error metrics and calculate them for **each model** (RNN, LSTM, GRU). Compare your results with the paper‚Äôs findings to see how closely they match.\n",
        "\n",
        "### üìä Comparison of Evaluation Metrics: Our Models vs. Paper Results\n",
        "\n",
        "| Model      | MAE       | RMSE      | R¬≤       | MAPE (%) | Source         |\n",
        "|------------|-----------|-----------|----------|-----------|----------------|\n",
        "| **RNN**    | 0.2463    | 0.2821    | -1.4959  | 44.8800   | Ours           |\n",
        "| **LSTM**   | 0.0465    | 0.0576    | 0.8961   | 8.8601    | Ours           |\n",
        "| **GRU**    | 0.0326    | 0.0446    | 0.9376   | 6.1914    | Ours           |\n",
        "| **LSTM**   | 667.6389  | 896.7875  | 0.9425   | 3.9412    | Paper          |\n",
        "| **GRU**    | 531.0581  | 718.0000  | 0.9631   | 3.0547    | Paper          |\n",
        "\n",
        "\n",
        "üõ† *Your task:* Implement the evaluation metrics below. (15 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-07T20:10:07.172930Z",
          "iopub.status.busy": "2025-04-07T20:10:07.172669Z",
          "iopub.status.idle": "2025-04-07T20:10:07.183261Z",
          "shell.execute_reply": "2025-04-07T20:10:07.182562Z",
          "shell.execute_reply.started": "2025-04-07T20:10:07.172908Z"
        },
        "id": "r-raALLdzBM2",
        "outputId": "94b0ecea-c3b6-4663-aa56-c0cd43f5897f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def calculate_metrics(predictions, actual):\n",
        "    mae = mean_absolute_error(actual, predictions)\n",
        "    rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
        "    mape = np.mean(np.abs((actual - predictions) / actual)) * 100\n",
        "    r2 = r2_score(actual, predictions)\n",
        "    return {\n",
        "        \"MAE\": round(mae, 4),\n",
        "        \"RMSE\": round(rmse, 4),\n",
        "        \"MAPE (%)\": round(mape, 4),\n",
        "        \"R^2\": round(r2, 4)\n",
        "    }\n",
        "\n",
        "print(\"RNN Metrics (Unscaled):\", calculate_metrics(rnn_preds, rnn_targets))\n",
        "print(\"LSTM Metrics (Unscaled):\", calculate_metrics(lstm_preds, lstm_targets))\n",
        "print(\"GRU Metrics (Unscaled):\", calculate_metrics(gru_preds, gru_targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-27T16:39:15.333925Z",
          "iopub.status.busy": "2025-03-27T16:39:15.333720Z",
          "iopub.status.idle": "2025-03-27T16:39:15.457777Z",
          "shell.execute_reply": "2025-03-27T16:39:15.456751Z",
          "shell.execute_reply.started": "2025-03-27T16:39:15.333907Z"
        },
        "id": "xj8ECbA1tmLK",
        "outputId": "3900cfcd-5474-4186-b627-722d82db2805",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Fill missing values for all features\n",
        "filled_data = data.copy()\n",
        "for column in ['Open', 'High', 'Low', 'Volume', 'Adj Close']:\n",
        "    filled_data[column] = (\n",
        "    filled_data[column]\n",
        "    .interpolate(method='linear')\n",
        "    .bfill()\n",
        "    .ffill()\n",
        ")\n",
        "\n",
        "# WE WILL USE THESE IN ARIMA PART AS INPUTS OF MODELS\n",
        "train_data = filled_data.iloc[:-int(0.3 * len(filled_data))]\n",
        "test_data = filled_data.iloc[-int(0.3 * len(filled_data)):]\n",
        "train_target = train_data['Adj Close']\n",
        "train_exog = train_data[['Open', 'High', 'Low', 'Volume']]\n",
        "test_exog = test_data[['Open', 'High', 'Low', 'Volume']]\n",
        "\n",
        "# ADF Test\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "result = adfuller(train_data['Adj Close'])\n",
        "print(f\"ADF Statistic: {result[0]}\")\n",
        "print(f\"p-value: {result[1]}\")\n",
        "print(f\"Critical Values: {result[4]}\")\n",
        "print(\"The series is stationary.\" if result[1] < 0.05 else \"The series is not stationary.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsCLKXfltmLK"
      },
      "source": [
        "## 4Ô∏è‚É£ ARIMA Model üìâ (15 Points)\n",
        "\n",
        "üìå Explain the **difference** between `ARIMA` and `SARIMA` models.\n",
        "\n",
        "  - **ARIMA (AutoRegressive Integrated Moving Average)** is a time series model used for forecasting non-seasonal data by combining:\n",
        "  - AR (AutoRegression): relationship between an observation and its past values.\n",
        "  - I (Integration): differencing the data to make it stationary.\n",
        "  - MA (Moving Average): relationship between an observation and residual errors from a moving average model applied to lagged observations.\n",
        "\n",
        "- **SARIMA (Seasonal ARIMA)** extends ARIMA by adding support for **seasonal patterns** in the data.  \n",
        "  SARIMA includes **seasonal AR**, **seasonal MA**, **seasonal differencing**, and a **seasonal period** parameter (usually 12 for monthly data, 4 for quarterly).\n",
        "\n",
        "> üß† **Key Difference:** SARIMA = ARIMA + Seasonal Terms\n",
        "\n",
        "üìå List the **advantages** and **limitations** of `ARIMA`.\n",
        "\n",
        "**‚úÖ Advantages:**\n",
        "- Effective for **univariate** time series forecasting.\n",
        "- Well-understood, interpretable with **clear mathematical foundation**.\n",
        "- Handles both trend and noise.\n",
        "- Widely used in econometrics and finance.\n",
        "\n",
        "**‚ùå Limitations:**\n",
        "- Assumes **linearity**; not suitable for nonlinear time series.\n",
        "- Requires **stationary data** (needs preprocessing via differencing).\n",
        "- Struggles with **seasonality** unless extended (via SARIMA).\n",
        "- Poor at **long-term forecasting** due to reliance on recent lags.\n",
        "\n",
        "üìå Explain the **mathematical formulation** of `ARIMA`, including its **parameters**.\n",
        "\n",
        "**Notation:** ARIMA(**p**, **d**, **q**)  \n",
        "Where:  \n",
        "- `p` = number of autoregressive (AR) terms  \n",
        "- `d` = number of differencing operations to make the series stationary  \n",
        "- `q` = number of moving average (MA) terms  \n",
        "\n",
        "**General Equation:**\n",
        "\n",
        "Let $ y_t $ be the original time series.\n",
        "\n",
        "- **Differencing (order d):**\n",
        "  $$\n",
        "  y'_t = y_t - y_{t-1} \\quad \\text{(for d=1)}\n",
        "  $$\n",
        "\n",
        "- **AR (AutoRegressive) part:**\n",
        "  $$\n",
        "  y'_t = \\phi_1 y'_{t-1} + \\phi_2 y'_{t-2} + \\dots + \\phi_p y'_{t-p}\n",
        "  $$\n",
        "\n",
        "- **MA (Moving Average) part:**\n",
        "  $$\n",
        "  + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\dots + \\theta_q \\varepsilon_{t-q} + \\varepsilon_t\n",
        "  $$\n",
        "\n",
        "- **Full ARIMA(p, d, q) model:**\n",
        "  $$\n",
        "  y_t = \\text{AR terms} + \\text{MA terms} + \\text{random error}\n",
        "  $$\n",
        "\n",
        "Where:\n",
        "- $ \\phi $ are AR coefficients,\n",
        "- $ \\theta $ are MA coefficients,\n",
        "- $ \\varepsilon_t $ is white noise.\n",
        "\n",
        "üìå Determine the **optimal parameters** for `ARIMA` and **report the results**.\n",
        "\n",
        "    Optimal ARIMA Order: (4, 1, 2)\n",
        "    Metrics (Unscaled): (1.0519, 1.4914, 1.6121, 0.9951)\n",
        "\n",
        "üìå Compare the results with **Table 6** from the paper.\n",
        "\n",
        "### üìä ARIMA Model Comparison: Ours vs. Paper\n",
        "\n",
        "| ARIMA Order      | MAE       | RMSE      | R¬≤       | MAPE (%) | Source         |\n",
        "|------------------|-----------|-----------|----------|-----------|----------------|\n",
        "| **(4,1,2)**       | 1.0519    | 1.4914    | 1.6121   | 0.9951    | Ours           |\n",
        "| **(1,1,5)**       | 4700.3681 | 5817.1785 | -0.0110  | 35.9599   | Paper      |\n",
        "| **(2,2,2)**       | 4898.0502 | 5922.1584 | -0.0476  | 36.6571   | Paper      |\n",
        "\n",
        "\n",
        "üìÑ [Reference Paper](https://www.ijournalse.org/index.php/ESJ/article/view/21497)\n",
        "\n",
        "üõ† *Your task:* Implement the ARIMA model below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIWc_Gqpx3Pb",
        "outputId": "9718ad0e-7986-417d-f571-1473e72cc365"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y pmdarima\n",
        "!pip install pmdarima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-22T20:40:45.801022Z",
          "iopub.status.busy": "2024-12-22T20:40:45.800686Z",
          "iopub.status.idle": "2024-12-22T20:41:08.946487Z",
          "shell.execute_reply": "2024-12-22T20:41:08.945480Z",
          "shell.execute_reply.started": "2024-12-22T20:40:45.800997Z"
        },
        "id": "4ErCQ8z9tmLK",
        "outputId": "ee05573e-2aae-4996-9376-2a9a5d535eb3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Train ARIMA model using auto_arima\n",
        "!pip install pmdarima\n",
        "from pmdarima import auto_arima\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
        "\n",
        "\n",
        "# Make sure to drop NaNs if any remain\n",
        "arima_series = adj_close_data['Adj Close'].dropna()\n",
        "\n",
        "\n",
        "#TO DO:Find optimal arima model using auto_arima\n",
        "\n",
        "arima_model = auto_arima(arima_series, seasonal=False, trace=True,\n",
        "                         stepwise=True, suppress_warnings=True,\n",
        "                         error_action='ignore', approximation=False)\n",
        "\n",
        "print(f\"Optimal ARIMA Order: {arima_model.order}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-22T20:51:27.439737Z",
          "iopub.status.busy": "2024-12-22T20:51:27.439435Z",
          "iopub.status.idle": "2024-12-22T21:11:20.165706Z",
          "shell.execute_reply": "2024-12-22T21:11:20.164649Z",
          "shell.execute_reply.started": "2024-12-22T20:51:27.439716Z"
        },
        "id": "q2VFjdI2tmLK",
        "outputId": "4836431a-a7d2-4cf3-d976-b9dac6c08d46",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"statsmodels\")\n",
        "\n",
        "#TO DO: Predinct Arima outputs\n",
        "\n",
        "window_size = 50\n",
        "series = adj_close_data['Adj Close'].dropna().values\n",
        "arima_preds = []\n",
        "actual_vals = []\n",
        "\n",
        "print(\"Processing ARIMA predictions:\")\n",
        "for i in tqdm(range(window_size, len(series))):\n",
        "    train_window = series[i - window_size:i]\n",
        "    actual_val = series[i]\n",
        "\n",
        "    try:\n",
        "        model = ARIMA(train_window, order=arima_model.order)\n",
        "        model_fit = model.fit()\n",
        "        forecast = model_fit.forecast()[0]\n",
        "        scalar_forecast = float(forecast[0])\n",
        "\n",
        "    except:\n",
        "        scalar_forecast = train_window[-1]  # fallback if model fails\n",
        "\n",
        "    arima_preds.append(scalar_forecast)\n",
        "    actual_vals.append(actual_val)\n",
        "\n",
        "# Convert to numpy arrays for metrics\n",
        "arima_preds = np.array(arima_preds)\n",
        "actual_vals = np.array(actual_vals)\n",
        "\n",
        "# Calculate and print metrics\n",
        "arima_metrics = calculate_metrics(arima_preds, actual_vals)\n",
        "print(\"ARIMA Metrics (Unscaled):\", tuple(arima_metrics.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "execution": {
          "iopub.execute_input": "2024-12-22T21:11:31.043523Z",
          "iopub.status.busy": "2024-12-22T21:11:31.043237Z",
          "iopub.status.idle": "2024-12-22T21:11:31.315066Z",
          "shell.execute_reply": "2024-12-22T21:11:31.314271Z",
          "shell.execute_reply.started": "2024-12-22T21:11:31.043501Z"
        },
        "id": "rVhrpQGItmLL",
        "outputId": "b47f2508-9908-4a4b-c386-a6870a994ead",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#TO DO: Plot ARIMA vs actual\n",
        "plot_predictions(arima_preds, actual_vals, \"ARIMA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-22T21:17:51.543163Z",
          "iopub.status.busy": "2024-12-22T21:17:51.542878Z",
          "iopub.status.idle": "2024-12-22T21:20:22.908554Z",
          "shell.execute_reply": "2024-12-22T21:20:22.907573Z",
          "shell.execute_reply.started": "2024-12-22T21:17:51.543142Z"
        },
        "id": "OPaXBhYt8jxS",
        "outputId": "2d7d0ab6-68c5-4037-f4f3-46ed4b7e836b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "order_combinations = [(3,1,2)]\n",
        "seasonal_combinations = [(3,1,1,12)]\n",
        "# Initialize variables to store the best results\n",
        "best_aic = float(\"inf\")\n",
        "best_order = None\n",
        "best_seasonal_order = None\n",
        "best_model = None\n",
        "\n",
        "# Grid search over all parameter combinations\n",
        "for order in order_combinations:\n",
        "    for seasonal_order in seasonal_combinations:\n",
        "        try:\n",
        "            #TO DO: Train SARIMA model\n",
        "            # Train SARIMA model\n",
        "            model = SARIMAX(adj_close_data['Adj Close'], order=order, seasonal_order=seasonal_order)\n",
        "            model_fit = model.fit(disp=False)\n",
        "\n",
        "            #TO DO: Check AIC\n",
        "            if model_fit.aic < best_aic:\n",
        "                best_aic = model_fit.aic\n",
        "                best_order = order\n",
        "                best_seasonal_order = seasonal_order\n",
        "                best_model = model_fit\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "\n",
        "print(f\"Best SARIMA Model: Order={best_order}, Seasonal_Order={best_seasonal_order}, AIC={best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-22T21:42:49.949050Z",
          "iopub.status.busy": "2024-12-22T21:42:49.948708Z",
          "iopub.status.idle": "2024-12-22T21:43:02.876932Z",
          "shell.execute_reply": "2024-12-22T21:43:02.875716Z",
          "shell.execute_reply.started": "2024-12-22T21:42:49.949026Z"
        },
        "id": "c-2JnwEi8z4E",
        "outputId": "a7eefd5d-e853-481c-bba1-0e83309bb472",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#TO DO: Batch forecasting for SARIMA\n",
        "\n",
        "# Define the forecast range\n",
        "start_idx = 0\n",
        "end_idx = len(adj_close_data) - 1\n",
        "\n",
        "# Generate predictions\n",
        "pred_results = best_model.get_prediction(start=start_idx, end=end_idx)\n",
        "sarima_preds = pred_results.predicted_mean.values  # 1D forecast values\n",
        "\n",
        "# Actual values for comparison\n",
        "sarima_actuals = adj_close_data['Adj Close'].iloc[start_idx:end_idx + 1].values\n",
        "\n",
        "# Evaluate\n",
        "metrics = calculate_metrics(sarima_preds, sarima_actuals)\n",
        "print(\"SARIMA Forecast Using Best Model:\", (metrics[\"MAE\"], metrics[\"RMSE\"], metrics[\"R^2\"], metrics[\"MAPE (%)\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "execution": {
          "iopub.execute_input": "2024-12-22T21:43:02.879395Z",
          "iopub.status.busy": "2024-12-22T21:43:02.878762Z",
          "iopub.status.idle": "2024-12-22T21:43:03.137389Z",
          "shell.execute_reply": "2024-12-22T21:43:03.136527Z",
          "shell.execute_reply.started": "2024-12-22T21:43:02.879355Z"
        },
        "id": "SMfmggy383gT",
        "outputId": "2bfd439b-acd6-4988-9afb-505724aa3143",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#TO DO: Plot SARIMA vs actual\n",
        "\n",
        "plot_predictions(sarima_preds, sarima_actuals, \"SARIMA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2_D0coMDJEM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 6982878,
          "sourceId": 11186162,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7077565,
          "sourceId": 11315147,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
