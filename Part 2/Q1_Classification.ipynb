{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CxAp8SCMZg2"
   },
   "source": [
    "<div align=\"center\">\n",
    "    <font color=\"0F5298\" size=\"7\">\n",
    "        Deep Learning <br>\n",
    "    </font>\n",
    "    <font color=\"2565AE\" size=\"5\">\n",
    "        CE Department <br>\n",
    "        Spring 2024 - Prof. Soleymani Baghshah <br>\n",
    "    </font>\n",
    "    <font color=\"3C99D\" size=\"5\">\n",
    "        HW2 Practical <br>\n",
    "    </font>\n",
    "    <font color=\"696880\" size=\"5\">\n",
    "        30 Points\n",
    "    </font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIvKIBwA-OF5"
   },
   "outputs": [],
   "source": [
    "FULLNAME = 'YOUR NAME'\n",
    "STD_ID = 'YOUR ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvjgtf0s9_Uy"
   },
   "source": [
    "In this notebook, we aim to perform **classification** on images from the **CIFAR10** dataset using CNN networks. First, we load the dataset and apply the necessary transformations for normalization and augmentation. After that, we visualize some samples. Once we familiarize ourselves with the dataset, we proceed to design the desired convolutional network, which is explained in the relevant section. After designing the model, we move on to training and evaluating it. At the end of the first section, we analyze the feature space from different perspectives. First, using the KNN method, we examine the closest samples to each other in the feature space. Then, we cluster the data and finally visualize the outputs of the intermediate layers of the model.\n",
    "\n",
    "In the second part of the notebook, we perform a simple transfer learning task on the trained model from the first section but using a new dataset, **CIFAR100**. To do this, we modify the final layer of the network and retrain it. Further details are provided in the relevant section. Finally, we evaluate the model’s accuracy on the new task and analyze the extracted features and how well the model generalizes. After designing and training the model, we will further analyze the extracted feature space. Finally, we will evaluate the generalization ability of the model and its extracted features on a new dataset,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAa6g3BcFCOi"
   },
   "source": [
    "# CIFAR10 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGfwMyZ7vm_f"
   },
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GsrCzWTOIhI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIv1Mpsbvt8v"
   },
   "source": [
    "## Device\n",
    "\n",
    "Set device to work with (GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2uGuIUtwSFAR",
    "outputId": "21e0cbae-39ef-4cc1-a5a4-1d18f43e17c4"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4T4AL0cv1Jm"
   },
   "source": [
    "## Transforms & Dataset & Dataloader\n",
    "\n",
    "Here, you should download and load the dataset with the desire transforms. After that, you should split train dataset to train and validation sets. Finally, define the dataloaders for `train`, `validation` and `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E6TT8whO9N4"
   },
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3UuPXFQOSDX",
    "outputId": "86ed0f89-e1d3-4b04-b890-8ede5518084a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data Transforms\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
    "])\n",
    "\n",
    "# Load Train Data\n",
    "full_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "\n",
    "# Split Train and Validation Data\n",
    "val_size = 5000\n",
    "train_size = len(full_train_dataset) - val_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# Load Test Data\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Define Data Loaders\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-C-YjLZtwnq2"
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Visualize 5 random images from each class in different columns\n",
    "\n",
    "- **Hint**:  You can use `plt.subplots` for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 795
    },
    "id": "taCjx6n_OtZg",
    "outputId": "631633f5-3a38-4605-a8b0-a75357dd4286"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find 5 Images from Each Class\n",
    "fig, axs = plt.subplots(5, len(classes), figsize=(15, 7))\n",
    "class_counts = {cls: 0 for cls in classes}\n",
    "for img, label in full_train_dataset:\n",
    "    cls_name = classes[label]\n",
    "    if class_counts[cls_name] < 5:\n",
    "        ax = axs[class_counts[cls_name]][label]\n",
    "        img_to_show = img.clone() * torch.tensor(cifar10_std).view(3,1,1) + torch.tensor(cifar10_mean).view(3,1,1)\n",
    "        ax.imshow(img_to_show.permute(1,2,0))\n",
    "        ax.axis('off')\n",
    "        if class_counts[cls_name] == 0:\n",
    "            ax.set_title(cls_name)\n",
    "        class_counts[cls_name] += 1\n",
    "    if all(v >= 5 for v in class_counts.values()):\n",
    "        break\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ja-L0f1wybzU"
   },
   "source": [
    "## Model\n",
    "\n",
    "Define your model here from scratch (You are not allowed to use the existing models in pytorch)\n",
    "\n",
    "**NOTICE:** The model that you will have defined outputs a vector containing 10 numbers (for each class). Define a \"feature space\" that is a vector of size *N* (where *N > 10*) right before the last layer (You can then have a last layer like `nn.Linear(N, 10)`). See the image below to get a better understanding. We will use this later (we want to access the feature space of a sample when the sample is given to the model). The model tries to learn a representation of the samples in this feature space and we will see how good it could do this in later sections.\n",
    "\n",
    "![Feature Space In Neural Network](https://i.postimg.cc/28Qjcn9D/feature-space-vis.png)\n",
    "\n",
    "- **Hint I**: Our goal is to get accuracy above *90%* on testset. Our suggestion is to implement ResNet (ResNet18 could be a viable choice)\n",
    "  - You can learn the network's structure and implementation online (Youtube, ...) and then implmenet it yourself and make changes to enhance it's performance on our task **(YOU SHOULD NOT COPY THE CODE!!! OTHERWISE, YOU'LL BE PENALIZED!!!)**\n",
    "\n",
    "- **Hint II**: When defining your model, pay attension to the **NOTICE** part in the above. It's also better to read the \"Exploring the feature space\" section beforehand.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUYoc5gVVkTP"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Implement Model\n",
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, feature_dim=256):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "        )\n",
    "        self.fc_feat = nn.Linear(256, feature_dim)\n",
    "        self.fc_out = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        features = self.fc_feat(x)\n",
    "        features = F.relu(features)\n",
    "        logits = self.fc_out(features)\n",
    "        return logits, features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYp77Euaz_5u"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odR5mfCA0Eqy"
   },
   "source": [
    "### Model instantiation\n",
    "\n",
    "Create an instance of your model and move it to `device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3PjKY_oSBkg"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define Model\n",
    "model = SimpleResNet(num_classes=10, feature_dim=256).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8zn5eLs0bBS"
   },
   "source": [
    "### Criterion & Optimizater\n",
    "\n",
    "Define `criterion` and `optimizer` (Or `scheduler`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEd5yXt3SL2T"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gth9e1k70uAI"
   },
   "source": [
    "### Train loop\n",
    "\n",
    "Train your model\n",
    "\n",
    "Tasks:\n",
    "- [ ] Things that are needed to be printed in each epoch:\n",
    "  - Number of epoch\n",
    "  - Train loss\n",
    "  - Train accuracy\n",
    "  - Validation loss\n",
    "  - Validation accuracy\n",
    "- [ ] save train/validation loss and accuracy (of each epoch) in an array for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VvYTIClSRC5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Implement Training Loop\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    return running_loss/total, correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0p79bJ30n83E"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Implement Validation Loop\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs, _ = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return running_loss/total, correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VPw6w4AtTGe",
    "outputId": "5401f12f-4302-4aab-88ee-28aa386fce2e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train The Model\n",
    "epochs = 10\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "for epoch in range(epochs):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "    scheduler.step()\n",
    "    train_losses.append(tr_loss); val_losses.append(val_loss)\n",
    "    train_accs.append(tr_acc); val_accs.append(val_acc)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss {tr_loss:.4f} Acc {tr_acc:.3f} | Val Loss {val_loss:.4f} Acc {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qh2FEO6bhHTB"
   },
   "source": [
    "### Save Model\n",
    "\n",
    "Since changes need to be made to the model later on, it is advisable to save your model to avoid having to retrain it in case of any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIpdn3eHu52C",
    "outputId": "314a67cf-af32-4217-cbf7-1bf367647df9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save Model\n",
    "ckpt_path = 'cifar10_model.pth'\n",
    "torch.save({'model_state': model.state_dict(), 'feature_dim': model.feature_dim}, ckpt_path)\n",
    "print(f\"Model saved to {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwg7D6sv1kFL"
   },
   "source": [
    "### Visualize Loss and Accuracy plot\n",
    "\n",
    "Using the arrays that you have (from task 2 in the above section), visualize two plots: Accuracy plot (train and validation together) and Loss plot (train and validation together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "4dKB3gVmEaVG",
    "outputId": "14ea32e9-f901-4f4c-ce06-4c7cc3c49e2d"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Val')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_accs, label='Train')\n",
    "plt.plot(val_accs, label='Val')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF_oCC3p2Q3C"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Test your trained model (using the Test Dataloader that you have). Our goal is to reach an accuracy above `90%`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzkNN4sMb3lK",
    "outputId": "5a3e8080-2f26-4742-f834-f4334431307b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run Model on Testset\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs, _ = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCKR1Xac2keH"
   },
   "source": [
    "## Visualize incorrectly predicted samples from testset\n",
    "\n",
    "Visualize *24* random images from testset that are incorrectly predicted by the model. Note that if you used normalization in the transform function for loading the data, you will need to unnormalize the images before displaying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "Ew2KUBIWcG35",
    "outputId": "dcbd9a1c-2b26-4803-aa3c-ef9e32613dcd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot Samples with Wrong Predicted Classes\n",
    "wrong_indices = [i for i, (p, l) in enumerate(zip(all_preds, all_labels)) if p != l]\n",
    "fig, axs = plt.subplots(4, 6, figsize=(12,8))\n",
    "axs = axs.flatten()\n",
    "shown = 0\n",
    "for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "    for i in range(images.size(0)):\n",
    "        global_idx = batch_idx * test_loader.batch_size + i\n",
    "        if global_idx in wrong_indices and shown < len(axs):\n",
    "            img = images[i].cpu() * torch.tensor(cifar10_std).view(3,1,1) + torch.tensor(cifar10_mean).view(3,1,1)\n",
    "            axs[shown].imshow(img.permute(1,2,0))\n",
    "            axs[shown].set_title(f\"T:{classes[labels[i]]}\n",
    "P:{classes[all_preds[global_idx]]}\")\n",
    "            axs[shown].axis('off')\n",
    "            shown += 1\n",
    "    if shown >= len(axs):\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJdFFFGL9T7L"
   },
   "source": [
    "## Exploring the feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTQ0aX0j9c7q"
   },
   "source": [
    "### Calculate the feature space for all training samples\n",
    "\n",
    "You have trained and evaluated your model. Now, for each sample in the trainset, calculate it's \"feature space\" discussed in the model section. The result of this section should be a tensor of size `(50000, N)` saved in a variable (for later usage)\n",
    "\n",
    "- **Hint 1:** define a tensor with dimension `(50000, N)` where *50000* is the size of the trainset and *N* is the dimension of the feature space\n",
    "\n",
    "- **Hint 2:** Pay attension to the `shuffle` attribute of your train dataloader (If needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbMzEiuqyP20"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find Features and Put Them in One Dimensional List\n",
    "model.eval()\n",
    "train_features = []\n",
    "train_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=False, num_workers=2):\n",
    "        images = images.to(device)\n",
    "        _, feats = model(images)\n",
    "        train_features.append(feats.cpu())\n",
    "        train_labels.append(labels)\n",
    "train_features = torch.cat(train_features, dim=0)\n",
    "train_labels = torch.cat(train_labels, dim=0)\n",
    "print(train_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDoLqddo-WJV"
   },
   "source": [
    "### K Nearest Neighbor in feature space\n",
    "\n",
    "You already have calculated the feature spaces for trainset ($S$) in the previous section\n",
    "\n",
    "1. Get 5 random samples from testset which are correctly predicted by the model.\n",
    "2. for each sample, calculate it's \"feature space\" ($X$)\n",
    "3. for each sample, calculate it's *5* nearest neighbors in \"feature space\" in the trainset (by comparing $X$ to each row in $S$) and visualize them\n",
    "\n",
    "**Note:** Your visualization should be something like the below picture\n",
    "\n",
    "**Hint:** To find the nearest neighbors in the feature space, you can use any library of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PvPFZ5_7SP9H",
    "outputId": "ae78ab16-0227-47e7-ab85-36d9898515ff"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find Features List for Test Samples\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "model.eval()\n",
    "correct_samples = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        logits, feats = model(images)\n",
    "        preds = logits.argmax(dim=1).cpu()\n",
    "        for img, lab, pred, feat in zip(images.cpu(), labels, preds, feats.cpu()):\n",
    "            if lab == pred:\n",
    "                correct_samples.append((img, lab.item(), feat))\n",
    "        if len(correct_samples) >= 5:\n",
    "            break\n",
    "\n",
    "feats_mat = torch.stack([f for _,_,f in correct_samples])\n",
    "labels_correct = [l for _, l, _ in correct_samples]\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(train_features)\n",
    "dists, idxs = knn.kneighbors(feats_mat)\n",
    "\n",
    "fig, axs = plt.subplots(len(correct_samples), 6, figsize=(12,8))\n",
    "for row, (img, lab, feat) in enumerate(correct_samples):\n",
    "    img_disp = img.cpu() * torch.tensor(cifar10_std).view(3,1,1) + torch.tensor(cifar10_mean).view(3,1,1)\n",
    "    axs[row,0].imshow(img_disp.permute(1,2,0))\n",
    "    axs[row,0].set_title(f\"Query:{classes[lab]}\")\n",
    "    axs[row,0].axis('off')\n",
    "    for k in range(5):\n",
    "        tr_idx = idxs[row, k]\n",
    "        tr_img, tr_lab = full_train_dataset[tr_idx]\n",
    "        tr_img_disp = tr_img * torch.tensor(cifar10_std).view(3,1,1) + torch.tensor(cifar10_mean).view(3,1,1)\n",
    "        axs[row,k+1].imshow(tr_img_disp.permute(1,2,0))\n",
    "        axs[row,k+1].set_title(classes[tr_lab])\n",
    "        axs[row,k+1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X9aAFY3_g3w"
   },
   "source": [
    "### TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3DC15RI_loC"
   },
   "source": [
    "1. Sample $M$ ($2000$ would be enought) random samples from the trainset feature space (calculated in the above sections)\n",
    "2. Now you a vector of size `(M, N)` where $N$ is the dimension of the feature space\n",
    "3. Using TSNE reduce $N$ to $2$ (Now you have a vector of size `(M, 2)`)\n",
    "4. Print the shape of the output\n",
    "\n",
    "**Hint:** You can use `sklearn.manifold.TSNE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjjV74qNe0dN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get Samples\n",
    "M = 2000\n",
    "indices = torch.randperm(train_features.size(0))[:M]\n",
    "feat_sample = train_features[indices]\n",
    "label_sample = train_labels[indices]\n",
    "\n",
    "# Use TSNE\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=30)\n",
    "feat_tsne = tsne.fit_transform(feat_sample.numpy())\n",
    "print(feat_tsne.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tRoZPOJAv2i"
   },
   "source": [
    "Visualize the points in a 2D plane (Set color of each point based on it's class)\n",
    "\n",
    "**Notice:** Your visualization should be something like the below image\n",
    "\n",
    "**Hint:** Use `plt.scatter(x, y, c=labels)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 831
    },
    "id": "qsj2zTP6XeLX",
    "outputId": "ba095807-ac4b-4ee9-ada2-3c135f91ecb6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot Results\n",
    "plt.figure(figsize=(8,6))\n",
    "scatter = plt.scatter(feat_tsne[:,0], feat_tsne[:,1], c=label_sample.numpy(), cmap='tab10', s=10)\n",
    "plt.legend(*scatter.legend_elements(), title=\"Classes\", bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "plt.title('t-SNE of Feature Space')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmf38tlk-ZOV"
   },
   "source": [
    "### Feature Map\n",
    "\n",
    "\n",
    "In this part, we are going to visualize the output of one of the convolutional layers to see what features they focus on.\n",
    "\n",
    "First, let's select a random image from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pLxGaxuNYz3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Select an Image\n",
    "sample_img, sample_label = test_dataset[random.randrange(len(test_dataset))]\n",
    "plt.imshow((sample_img * torch.tensor(cifar10_std).view(3,1,1) + torch.tensor(cifar10_mean).view(3,1,1)).permute(1,2,0))\n",
    "plt.title(f\"Label: {classes[sample_label]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQnpfY6nNLaU"
   },
   "source": [
    "Now, we are going to *clip* our model at different points to get different intermediate representation.\n",
    "* Clip your model at least at one point and plot the filters output. You can use the output of first Resnet block.\n",
    "\n",
    "In order to clip the model, you can use `model.children()` method. For example, to get output only after the first 2 layers, you can do:\n",
    "\n",
    "```\n",
    "clipped = nn.Sequential(\n",
    "    *list(model.children()[:2])\n",
    ")\n",
    "intermediate_output = clipped(input)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwzGiNZIUmbw",
    "outputId": "c52e4768-7a60-47a9-bae3-4357195fdecc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get Intermediate Output\n",
    "clipped = nn.Sequential(*list(model.children())[:3])  # up to conv3\n",
    "with torch.no_grad():\n",
    "    inter_out = clipped(sample_img.unsqueeze(0).to(device)).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "id": "ZhlqDrGTV7HR",
    "outputId": "7ff5a1e4-8e65-4a32-a319-5b10ee7e6536"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot Intermediate Output\n",
    "plot_intermediate_output(inter_out, title='Feature maps after clipping')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRZlTFanEFSU"
   },
   "source": [
    "## CIFAR100\n",
    "\n",
    "In this section, we aim to test the trained model on a different dataset. For this purpose, we will use the CIFAR100 dataset, which is similar to CIFAR10 but has different types and numbers of classes. In order for the model to perform well on the new dataset, we need to modify the last layer of the model. As you know from the previous section, the last layer of the model is a linear layer that maps the features to the number of classes. In this section, due to the increase in the number of classes, we plan to modify this layer and train the new linear layer with the new dataset. Note that all other layers and weights of the model will remain fixed and unchanged; only the last layer will be retrained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0ppwAjiP0Kf"
   },
   "source": [
    "### Dataset & Dataloader\n",
    "\n",
    "Here, you should download and load the dataset with the desire transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OG1HTFK8BLky",
    "outputId": "9463a541-4a0b-4808-bb63-f098fe88836a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data Transforms\n",
    "cifar100_mean = (0.5071, 0.4867, 0.4408)\n",
    "cifar100_std = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "train_transform_100 = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar100_mean, cifar100_std),\n",
    "])\n",
    "\n",
    "test_transform_100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar100_mean, cifar100_std),\n",
    "])\n",
    "\n",
    "# Load Train and Test Data\n",
    "cifar100_train = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform_100)\n",
    "cifar100_test = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform_100)\n",
    "\n",
    "# Define Data Loaders\n",
    "train_loader_100 = torch.utils.data.DataLoader(cifar100_train, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader_100 = torch.utils.data.DataLoader(cifar100_test, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ps1PYu8VpaGD",
    "outputId": "77b5f7a5-af61-4ef5-f94e-adc1a8d92658"
   },
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"apple\", \"aquarium_fish\", \"baby\", \"bear\", \"beaver\", \"bed\", \"bee\",\n",
    "    \"beetle\", \"bicycle\", \"bottle\", \"bowl\", \"boy\", \"bridge\", \"bus\", \"butterfly\", \"camel\", \"can\", \"castle\", \"caterpillar\", \"cattle\", \"chair\", \"chimpanzee\",\n",
    "    \"clock\", \"cloud\", \"cockroach\", \"couch\", \"crab\", \"crocodile\", \"cup\", \"dinosaur\", \"dolphin\", \"elephant\", \"flatfish\", \"forest\", \"fox\", \"girl\", \"hamster\",\n",
    "    \"house\", \"kangaroo\", \"keyboard\", \"lamp\", \"lawn_mower\", \"leopard\", \"lion\", \"lizard\", \"lobster\", \"man\", \"maple_tree\", \"motorcycle\", \"mountain\", \"mouse\",\n",
    "    \"mushroom\", \"oak_tree\", \"orange\", \"orchid\", \"otter\", \"palm_tree\", \"pear\", \"pickup_truck\", \"pine_tree\", \"plain\", \"plate\", \"poppy\", \"porcupine\", \"possum\",\n",
    "    \"rabbit\", \"raccoon\", \"ray\", \"road\", \"rocket\", \"rose\", \"sea\", \"seal\", \"shark\", \"shrew\", \"skunk\", \"skyscraper\", \"snail\", \"snake\", \"spider\",\n",
    "    \"squirrel\", \"streetcar\", \"sunflower\", \"sweet_pepper\", \"table\", \"tank\", \"telephone\", \"television\", \"tiger\", \"tractor\", \"train\",\n",
    "    \"trout\", \"tulip\", \"turtle\", \"wardrobe\", \"whale\", \"willow_tree\", \"wolf\", \"woman\", \"worm\"\n",
    "]\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmznidsgQJCb"
   },
   "source": [
    "### Visualization\n",
    "\n",
    "Visualize 1 random images from each class.\n",
    "\n",
    "- **Hint**:  You can use `plt.subplots` for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uxAFthPhphs1",
    "outputId": "e4180849-13d7-4487-e132-75ba63ea1cef"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find One Image from Each Class\n",
    "fig, axs = plt.subplots(10, 10, figsize=(18,18))\n",
    "seen = {}\n",
    "for img, lbl in cifar100_train:\n",
    "    if lbl not in seen:\n",
    "        seen[lbl] = img\n",
    "    if len(seen) == len(classes):\n",
    "        break\n",
    "for idx, (lbl, img) in enumerate(seen.items()):\n",
    "    r, c = divmod(idx, 10)\n",
    "    img_disp = img * torch.tensor(cifar100_std).view(3,1,1) + torch.tensor(cifar100_mean).view(3,1,1)\n",
    "    axs[r][c].imshow(img_disp.permute(1,2,0))\n",
    "    axs[r][c].set_title(classes[lbl], fontsize=7)\n",
    "    axs[r][c].axis('off')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozMbhmKmQQwu"
   },
   "source": [
    "### Modify Model\n",
    "\n",
    "Change the final linear layer of the model according to the new number of classes And freeze all other layers.\n",
    "- Do not forgot to move model to `device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYrxVAC5RDN4"
   },
   "outputs": [],
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "# Freeze All Layers\n",
    "\n",
    "# Modify The Last Linear Layer\n",
    "\n",
    "# Move Model to Device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gwii0O3vRCrc"
   },
   "source": [
    "### Criterion & Optimizater\n",
    "\n",
    "Define `criterion` and `optimizer` (Or `scheduler`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f9xW643Rpvp"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion_100 = nn.CrossEntropyLoss()\n",
    "optimizer_100 = optim.Adam(model.fc_out.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzfUXNh8RvoP"
   },
   "source": [
    "### Train\n",
    "\n",
    "Train the Model (Only Last Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yscorzmObdoc",
    "outputId": "7e973da2-762d-4c69-8544-c86db7c1dacb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train The Model\n",
    "num_epochs_100 = 5\n",
    "model.train()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc_out.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for epoch in range(num_epochs_100):\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in train_loader_100:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer_100.zero_grad()\n",
    "        outputs, _ = model(images)\n",
    "        loss = criterion_100(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_100.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_100} Loss {running_loss/total:.4f} Acc {correct/total:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYuqrkQoR5rQ"
   },
   "source": [
    "### Test\n",
    "\n",
    "Evaluate the Model on CIFAR-100 Test Set. 40% accuracy is sufficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LemgWFc7PfZN",
    "outputId": "11af72eb-744a-491d-9b69-94ae32f04f32"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate Model on CIFAR100\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "all_preds_100, all_labels_100 = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader_100:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs, _ = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        all_preds_100.extend(preds.cpu().tolist())\n",
    "        all_labels_100.extend(labels.cpu().tolist())\n",
    "\n",
    "acc_100 = correct/total\n",
    "print(f\"CIFAR100 Test Accuracy: {acc_100:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CY8Udf2W1f6"
   },
   "source": [
    "### Question\n",
    "You might think that 40% accuracy is quite low. However, first of all, consider that the classification is done over 100 classes. The accuracy of a random model in this case is 1%. Also, we only changed one linear layer of the model, and the rest of the weights remained unchanged. What do you think is the reason the model can achieve a reasonably good generalization ability on a completely new dataset with just the change of one linear layer at the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpR-DF_ZdFne"
   },
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bv3ljI-SS_gS"
   },
   "source": [
    "### Visualize incorrectly predicted samples from testset\n",
    "\n",
    "Visualize *10* random images from testset that are incorrectly predicted by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "kF9kEWT5PoYQ",
    "outputId": "f915c13c-334d-4ae5-9d70-579c14b494f3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot Samples with Wrong Predicted Classes\n",
    "wrong_indices_100 = [i for i, (p,l) in enumerate(zip(all_preds_100, all_labels_100)) if p != l]\n",
    "fig, axs = plt.subplots(2,5, figsize=(12,5))\n",
    "axs = axs.flatten()\n",
    "shown=0\n",
    "for batch_idx, (images, labels) in enumerate(test_loader_100):\n",
    "    for i in range(images.size(0)):\n",
    "        gidx = batch_idx*test_loader_100.batch_size + i\n",
    "        if gidx in wrong_indices_100 and shown < len(axs):\n",
    "            img = images[i].cpu() * torch.tensor(cifar100_std).view(3,1,1) + torch.tensor(cifar100_mean).view(3,1,1)\n",
    "            axs[shown].imshow(img.permute(1,2,0))\n",
    "            axs[shown].set_title(f\"T:{classes[labels[i]]}\n",
    "P:{classes[all_preds_100[gidx]]}\", fontsize=8)\n",
    "            axs[shown].axis('off')\n",
    "            shown += 1\n",
    "    if shown >= len(axs):\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UNvJMk9T2qG"
   },
   "source": [
    "### Plot accuracy for each class\n",
    "\n",
    "Plot accuracy of model on testset for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 841
    },
    "id": "VYC1GlJfPrFY",
    "outputId": "dd065564-c37b-4a55-c7f3-8d330093b225"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate Accuracy for Each Class\n",
    "class_correct = [0 for _ in range(len(classes))]\n",
    "class_total = [0 for _ in range(len(classes))]\n",
    "for pred, lbl in zip(all_preds_100, all_labels_100):\n",
    "    class_total[lbl] += 1\n",
    "    if pred == lbl:\n",
    "        class_correct[lbl] += 1\n",
    "class_acc = [c/t if t>0 else 0 for c, t in zip(class_correct, class_total)]\n",
    "\n",
    "# Plot Class-Wise Accuracy\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(range(len(classes)), class_acc)\n",
    "plt.xticks(rotation=90, ticks=range(len(classes)), labels=classes, fontsize=6)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Per-class accuracy on CIFAR100')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDokbZ0uUI2f"
   },
   "source": [
    "### The classes with the best and worst accuracy\n",
    "\n",
    "Based on the results from the previous section, obtain the 5 classes with the best accuracy and the 5 classes with the worst accuracy on the testset, and display one sample from each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "iUkOpdphTBLC",
    "outputId": "dd1b5b44-b9e1-4e0b-a780-aa54dd8dac01"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find Top 5 Best and Worst Performing Classes\n",
    "acc_tensor = torch.tensor(class_acc)\n",
    "best_idx = torch.topk(acc_tensor, 5).indices.tolist()\n",
    "worst_idx = torch.topk(acc_tensor, 5, largest=False).indices.tolist()\n",
    "print(\"Best:\", [classes[i] for i in best_idx])\n",
    "print(\"Worst:\", [classes[i] for i in worst_idx])\n",
    "\n",
    "# Plot a Sample Image From Each of The Best and Worst Performing Classes\n",
    "fig, axs = plt.subplots(2,5, figsize=(12,6))\n",
    "for j, idx in enumerate(best_idx):\n",
    "    img, _ = next(x for x in cifar100_test if x[1]==idx)\n",
    "    img_disp = img * torch.tensor(cifar100_std).view(3,1,1) + torch.tensor(cifar100_mean).view(3,1,1)\n",
    "    axs[0,j].imshow(img_disp.permute(1,2,0))\n",
    "    axs[0,j].set_title(f\"Best: {classes[idx]}\")\n",
    "    axs[0,j].axis('off')\n",
    "for j, idx in enumerate(worst_idx):\n",
    "    img, _ = next(x for x in cifar100_test if x[1]==idx)\n",
    "    img_disp = img * torch.tensor(cifar100_std).view(3,1,1) + torch.tensor(cifar100_mean).view(3,1,1)\n",
    "    axs[1,j].imshow(img_disp.permute(1,2,0))\n",
    "    axs[1,j].set_title(f\"Worst: {classes[idx]}\")\n",
    "    axs[1,j].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhTPIE-fVW3U"
   },
   "source": [
    "### Question\n",
    "What do you think is the reason for the significant accuracy difference between different classes? What differences do you observe between the classes with the best and worst accuracy? Can you provide an analysis of the results and relate them to the model’s feature space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5o1IubxSeurd"
   },
   "source": [
    "Answer:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "interpreter": {
   "hash": "dff97b9f14a22ccae10e7a517c30d03fcee05a8617da6e3ca20a923077f5eb08"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
